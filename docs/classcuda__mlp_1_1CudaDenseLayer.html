<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: cuda_mlp::CudaDenseLayer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecuda__mlp.html">cuda_mlp</a></li><li class="navelem"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html">CudaDenseLayer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classcuda__mlp_1_1CudaDenseLayer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cuda_mlp::CudaDenseLayer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Fully connected layer with activation, using column-major matrices.  
 <a href="classcuda__mlp_1_1CudaDenseLayer.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:adf9209f0622597ed7f9a7cc9faabeab4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#adf9209f0622597ed7f9a7cc9faabeab4">CudaDenseLayer</a> (int <a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a1ff09702174422aa83a7179d36dd8f65">in</a>, int <a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a61e169a98f2a322016e11e36b9ef663a">out</a>, <a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742">ActivationType</a> act)</td></tr>
<tr class="memdesc:adf9209f0622597ed7f9a7cc9faabeab4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Construct a dense layer.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#adf9209f0622597ed7f9a7cc9faabeab4">More...</a><br /></td></tr>
<tr class="separator:adf9209f0622597ed7f9a7cc9faabeab4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ff09702174422aa83a7179d36dd8f65"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a1ff09702174422aa83a7179d36dd8f65">in</a> () const</td></tr>
<tr class="memdesc:a1ff09702174422aa83a7179d36dd8f65"><td class="mdescLeft">&#160;</td><td class="mdescRight">Input dimension.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#a1ff09702174422aa83a7179d36dd8f65">More...</a><br /></td></tr>
<tr class="separator:a1ff09702174422aa83a7179d36dd8f65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61e169a98f2a322016e11e36b9ef663a"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a61e169a98f2a322016e11e36b9ef663a">out</a> () const</td></tr>
<tr class="memdesc:a61e169a98f2a322016e11e36b9ef663a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Output dimension.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#a61e169a98f2a322016e11e36b9ef663a">More...</a><br /></td></tr>
<tr class="separator:a61e169a98f2a322016e11e36b9ef663a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a621d06093226718c1f10f0af1097e8b5"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a621d06093226718c1f10f0af1097e8b5">params_size</a> () const</td></tr>
<tr class="memdesc:a621d06093226718c1f10f0af1097e8b5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Total parameter count (weights + bias)  <a href="classcuda__mlp_1_1CudaDenseLayer.html#a621d06093226718c1f10f0af1097e8b5">More...</a><br /></td></tr>
<tr class="separator:a621d06093226718c1f10f0af1097e8b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8413a0ba423a5759746d137a2bcd30f5"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a8413a0ba423a5759746d137a2bcd30f5">weights_size</a> () const</td></tr>
<tr class="memdesc:a8413a0ba423a5759746d137a2bcd30f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Weights parameter count.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#a8413a0ba423a5759746d137a2bcd30f5">More...</a><br /></td></tr>
<tr class="separator:a8413a0ba423a5759746d137a2bcd30f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab88c2378b6fcc9826178bc980b35f1ab"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#ab88c2378b6fcc9826178bc980b35f1ab">bias_size</a> () const</td></tr>
<tr class="memdesc:ab88c2378b6fcc9826178bc980b35f1ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Bias parameter count.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#ab88c2378b6fcc9826178bc980b35f1ab">More...</a><br /></td></tr>
<tr class="separator:ab88c2378b6fcc9826178bc980b35f1ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a246c62e7e31df0e4e5cce8469bd526bd"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a246c62e7e31df0e4e5cce8469bd526bd">bind</a> (<a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *params, <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *grads)</td></tr>
<tr class="memdesc:a246c62e7e31df0e4e5cce8469bd526bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Bind parameter and gradient buffers.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#a246c62e7e31df0e4e5cce8469bd526bd">More...</a><br /></td></tr>
<tr class="separator:a246c62e7e31df0e4e5cce8469bd526bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af312d205604fe28f14391889ec836896"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#af312d205604fe28f14391889ec836896">init_stddev</a> () const</td></tr>
<tr class="memdesc:af312d205604fe28f14391889ec836896"><td class="mdescLeft">&#160;</td><td class="mdescRight">Recommended stddev for weight initialization.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#af312d205604fe28f14391889ec836896">More...</a><br /></td></tr>
<tr class="separator:af312d205604fe28f14391889ec836896"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9377e28aecd00f8fa1b4ffc64ec42ff"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#ab9377e28aecd00f8fa1b4ffc64ec42ff">forward</a> (<a class="el" href="classcuda__mlp_1_1CublasHandle.html">CublasHandle</a> &amp;handle, const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *input, int batch, <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *output)</td></tr>
<tr class="memdesc:ab9377e28aecd00f8fa1b4ffc64ec42ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward pass: Z = W*X + b, A = act(Z)  <a href="classcuda__mlp_1_1CudaDenseLayer.html#ab9377e28aecd00f8fa1b4ffc64ec42ff">More...</a><br /></td></tr>
<tr class="separator:ab9377e28aecd00f8fa1b4ffc64ec42ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8859956e7919c0f3304fcb4438510e9a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#a8859956e7919c0f3304fcb4438510e9a">backward</a> (<a class="el" href="classcuda__mlp_1_1CublasHandle.html">CublasHandle</a> &amp;handle, const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *input, const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *output, <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *next_grad, int batch, <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *prev_grad)</td></tr>
<tr class="memdesc:a8859956e7919c0f3304fcb4438510e9a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Backward pass: compute dW, db, and optionally dX.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#a8859956e7919c0f3304fcb4438510e9a">More...</a><br /></td></tr>
<tr class="separator:a8859956e7919c0f3304fcb4438510e9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0dc217bc81bb8f31007612ceed01425"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#af0dc217bc81bb8f31007612ceed01425">params_ptr</a> () const</td></tr>
<tr class="memdesc:af0dc217bc81bb8f31007612ceed01425"><td class="mdescLeft">&#160;</td><td class="mdescRight">Raw parameter pointer for this layer.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#af0dc217bc81bb8f31007612ceed01425">More...</a><br /></td></tr>
<tr class="separator:af0dc217bc81bb8f31007612ceed01425"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa125c6f7ed97f01e0e57d6767f4af4f2"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuda__mlp_1_1CudaDenseLayer.html#aa125c6f7ed97f01e0e57d6767f4af4f2">grads_ptr</a> () const</td></tr>
<tr class="memdesc:aa125c6f7ed97f01e0e57d6767f4af4f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Raw gradient pointer for this layer.  <a href="classcuda__mlp_1_1CudaDenseLayer.html#aa125c6f7ed97f01e0e57d6767f4af4f2">More...</a><br /></td></tr>
<tr class="separator:aa125c6f7ed97f01e0e57d6767f4af4f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Fully connected layer with activation, using column-major matrices. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="adf9209f0622597ed7f9a7cc9faabeab4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf9209f0622597ed7f9a7cc9faabeab4">&#9670;&nbsp;</a></span>CudaDenseLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">cuda_mlp::CudaDenseLayer::CudaDenseLayer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742">ActivationType</a>&#160;</td>
          <td class="paramname"><em>act</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Construct a dense layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>Input dimension </td></tr>
    <tr><td class="paramname">out</td><td>Output dimension </td></tr>
    <tr><td class="paramname">act</td><td>Activation type </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a8859956e7919c0f3304fcb4438510e9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8859956e7919c0f3304fcb4438510e9a">&#9670;&nbsp;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cuda_mlp::CudaDenseLayer::backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuda__mlp_1_1CublasHandle.html">CublasHandle</a> &amp;&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>next_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>prev_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Backward pass: compute dW, db, and optionally dX. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>cuBLAS handle </td></tr>
    <tr><td class="paramname">input</td><td>Input activations </td></tr>
    <tr><td class="paramname">output</td><td>Output activations </td></tr>
    <tr><td class="paramname">next_grad</td><td>Gradient w.r.t. output (out x batch), updated in-place </td></tr>
    <tr><td class="paramname">batch</td><td>Batch size </td></tr>
    <tr><td class="paramname">prev_grad</td><td>Optional gradient w.r.t. input (in x batch) </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcuda__mlp_1_1CudaDenseLayer_a8859956e7919c0f3304fcb4438510e9a_cgraph.png" border="0" usemap="#aclasscuda__mlp_1_1CudaDenseLayer_a8859956e7919c0f3304fcb4438510e9a_cgraph" alt=""/></div>
<map name="aclasscuda__mlp_1_1CudaDenseLayer_a8859956e7919c0f3304fcb4438510e9a_cgraph" id="aclasscuda__mlp_1_1CudaDenseLayer_a8859956e7919c0f3304fcb4438510e9a_cgraph">
<area shape="rect" title="Backward pass: compute dW, db, and optionally dX." alt="" coords="5,78,208,119"/>
<area shape="rect" href="namespacecuda__mlp.html#a735f4a6c3c580edaad22de5975c66b58" title="Check a cuBLAS API call and abort with a message on failure." alt="" coords="272,5,452,32"/>
<area shape="rect" href="classcuda__mlp_1_1CublasHandle.html#abeb7f0750e956a5f7de086ee4274f17e" title="Access the raw cuBLAS handle." alt="" coords="256,56,468,83"/>
<area shape="rect" href="namespacecuda__mlp.html#ab07f4773848ee1516671610a538c8ae2" title="Launch activation&#45;derivative kernel." alt="" coords="258,107,466,149"/>
<area shape="rect" href="namespacecuda__mlp.html#a171790bf97e28b10641775d966d496e0" title="Launch sum&#45;rows kernel." alt="" coords="257,173,467,200"/>
<area shape="rect" href="namespacecuda__mlp.html#ad0151301985ef1c9d60bc1a132c548d3" title="Check a CUDA API call and abort with a message on failure." alt="" coords="516,144,685,171"/>
</map>
</div>

</div>
</div>
<a id="ab88c2378b6fcc9826178bc980b35f1ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab88c2378b6fcc9826178bc980b35f1ab">&#9670;&nbsp;</a></span>bias_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t cuda_mlp::CudaDenseLayer::bias_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Bias parameter count. </p>

</div>
</div>
<a id="a246c62e7e31df0e4e5cce8469bd526bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a246c62e7e31df0e4e5cce8469bd526bd">&#9670;&nbsp;</a></span>bind()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cuda_mlp::CudaDenseLayer::bind </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>grads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Bind parameter and gradient buffers. </p>

</div>
</div>
<a id="ab9377e28aecd00f8fa1b4ffc64ec42ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9377e28aecd00f8fa1b4ffc64ec42ff">&#9670;&nbsp;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cuda_mlp::CudaDenseLayer::forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuda__mlp_1_1CublasHandle.html">CublasHandle</a> &amp;&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Forward pass: Z = W*X + b, A = act(Z) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>cuBLAS handle </td></tr>
    <tr><td class="paramname">input</td><td>Input matrix (in x batch) </td></tr>
    <tr><td class="paramname">batch</td><td>Batch size </td></tr>
    <tr><td class="paramname">output</td><td>Output matrix (out x batch) </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcuda__mlp_1_1CudaDenseLayer_ab9377e28aecd00f8fa1b4ffc64ec42ff_cgraph.png" border="0" usemap="#aclasscuda__mlp_1_1CudaDenseLayer_ab9377e28aecd00f8fa1b4ffc64ec42ff_cgraph" alt=""/></div>
<map name="aclasscuda__mlp_1_1CudaDenseLayer_ab9377e28aecd00f8fa1b4ffc64ec42ff_cgraph" id="aclasscuda__mlp_1_1CudaDenseLayer_ab9377e28aecd00f8fa1b4ffc64ec42ff_cgraph">
<area shape="rect" title="Forward pass: Z = W*X + b, A = act(Z)" alt="" coords="5,74,208,115"/>
<area shape="rect" href="namespacecuda__mlp.html#a735f4a6c3c580edaad22de5975c66b58" title="Check a cuBLAS API call and abort with a message on failure." alt="" coords="272,5,452,32"/>
<area shape="rect" href="classcuda__mlp_1_1CublasHandle.html#abeb7f0750e956a5f7de086ee4274f17e" title="Access the raw cuBLAS handle." alt="" coords="256,56,468,83"/>
<area shape="rect" href="namespacecuda__mlp.html#af291a8274e02d62ea667b6dd7c595bc6" title="Launch activation kernel." alt="" coords="258,107,466,133"/>
<area shape="rect" href="namespacecuda__mlp.html#abd24fc3c966441401f0f06926743e3e4" title="Launch add&#45;bias kernel." alt="" coords="261,157,463,184"/>
<area shape="rect" href="namespacecuda__mlp.html#ad0151301985ef1c9d60bc1a132c548d3" title="Check a CUDA API call and abort with a message on failure." alt="" coords="516,132,685,159"/>
</map>
</div>

</div>
</div>
<a id="aa125c6f7ed97f01e0e57d6767f4af4f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa125c6f7ed97f01e0e57d6767f4af4f2">&#9670;&nbsp;</a></span>grads_ptr()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a>* cuda_mlp::CudaDenseLayer::grads_ptr </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Raw gradient pointer for this layer. </p>

</div>
</div>
<a id="a1ff09702174422aa83a7179d36dd8f65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ff09702174422aa83a7179d36dd8f65">&#9670;&nbsp;</a></span>in()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int cuda_mlp::CudaDenseLayer::in </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Input dimension. </p>

</div>
</div>
<a id="af312d205604fe28f14391889ec836896"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af312d205604fe28f14391889ec836896">&#9670;&nbsp;</a></span>init_stddev()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a> cuda_mlp::CudaDenseLayer::init_stddev </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Recommended stddev for weight initialization. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcuda__mlp_1_1CudaDenseLayer_af312d205604fe28f14391889ec836896_cgraph.png" border="0" usemap="#aclasscuda__mlp_1_1CudaDenseLayer_af312d205604fe28f14391889ec836896_cgraph" alt=""/></div>
<map name="aclasscuda__mlp_1_1CudaDenseLayer_af312d205604fe28f14391889ec836896_cgraph" id="aclasscuda__mlp_1_1CudaDenseLayer_af312d205604fe28f14391889ec836896_cgraph">
<area shape="rect" title="Recommended stddev for weight initialization." alt="" coords="5,5,208,47"/>
<area shape="rect" href="namespacecuda__mlp.html#a6a3644353b56e2f50f80adcfc3f4ee00" title="scaling factor for initialization." alt="" coords="256,5,415,47"/>
</map>
</div>

</div>
</div>
<a id="a61e169a98f2a322016e11e36b9ef663a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61e169a98f2a322016e11e36b9ef663a">&#9670;&nbsp;</a></span>out()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int cuda_mlp::CudaDenseLayer::out </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Output dimension. </p>

</div>
</div>
<a id="af0dc217bc81bb8f31007612ceed01425"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0dc217bc81bb8f31007612ceed01425">&#9670;&nbsp;</a></span>params_ptr()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespacecuda__mlp.html#a97b413e947c6702ad0157e46d429853e">CudaScalar</a>* cuda_mlp::CudaDenseLayer::params_ptr </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Raw parameter pointer for this layer. </p>

</div>
</div>
<a id="a621d06093226718c1f10f0af1097e8b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a621d06093226718c1f10f0af1097e8b5">&#9670;&nbsp;</a></span>params_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t cuda_mlp::CudaDenseLayer::params_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Total parameter count (weights + bias) </p>

</div>
</div>
<a id="a8413a0ba423a5759746d137a2bcd30f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8413a0ba423a5759746d137a2bcd30f5">&#9670;&nbsp;</a></span>weights_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t cuda_mlp::CudaDenseLayer::weights_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Weights parameter count. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/cuda/<a class="el" href="layer_8cuh.html">layer.cuh</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
