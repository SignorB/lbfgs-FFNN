<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: src/cuda/kernels.cuh File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_adb0e0080591d240f7507da3cc422fe2.html">cuda</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">kernels.cuh File Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &quot;<a class="el" href="common_8cuh.html">common.cuh</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="cublas__handle_8cuh.html">cublas_handle.cuh</a>&quot;</code><br />
<code>#include &lt;cmath&gt;</code><br />
</div><div class="textblock"><div class="dynheader">
Include dependency graph for kernels.cuh:</div>
<div class="dyncontent">
<div class="center"><img src="kernels_8cuh__incl.png" border="0" usemap="#asrc_2cuda_2kernels_8cuh" alt=""/></div>
<map name="asrc_2cuda_2kernels_8cuh" id="asrc_2cuda_2kernels_8cuh">
<area shape="rect" title=" " alt="" coords="305,5,460,32"/>
<area shape="rect" href="common_8cuh.html" title=" " alt="" coords="180,80,287,107"/>
<area shape="rect" href="cublas__handle_8cuh.html" title=" " alt="" coords="311,80,454,107"/>
<area shape="rect" title=" " alt="" coords="478,80,541,107"/>
<area shape="rect" title=" " alt="" coords="152,155,221,181"/>
<area shape="rect" title=" " alt="" coords="350,155,415,181"/>
<area shape="rect" title=" " alt="" coords="5,155,128,181"/>
<area shape="rect" title=" " alt="" coords="245,155,325,181"/>
<area shape="rect" title=" " alt="" coords="440,155,539,181"/>
</map>
</div>
</div><div class="textblock"><div class="dynheader">
This graph shows which files directly or indirectly include this file:</div>
<div class="dyncontent">
<div class="center"><img src="kernels_8cuh__dep__incl.png" border="0" usemap="#asrc_2cuda_2kernels_8cuhdep" alt=""/></div>
<map name="asrc_2cuda_2kernels_8cuhdep" id="asrc_2cuda_2kernels_8cuhdep">
<area shape="rect" title=" " alt="" coords="251,5,405,32"/>
<area shape="rect" href="gd_8cuh.html" title=" " alt="" coords="5,80,128,107"/>
<area shape="rect" href="layer_8cuh.html" title=" " alt="" coords="152,80,291,107"/>
<area shape="rect" href="network_8cuh.html" title=" " alt="" coords="195,155,355,181"/>
<area shape="rect" href="lbfgs_8cuh.html" title=" " alt="" coords="365,80,504,107"/>
<area shape="rect" href="sgd_8cuh.html" title=" " alt="" coords="528,80,659,107"/>
</map>
</div>
</div><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacecuda__mlp"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html">cuda_mlp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:add042d87fe3ba725b24f107b67e53742"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742">cuda_mlp::ActivationType</a> : int { <a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742a32a843da6ea40ab3b17a3421ccdf671b">cuda_mlp::Linear</a> = 0
, <a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742acc132a41cab5676334f353a22a0aa5c5">cuda_mlp::Tanh</a> = 1
, <a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742add10d919fa85cf27fc78c0e06fe0b378">cuda_mlp::ReLU</a> = 2
, <a class="el" href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742a21eebb164e4b8b9bcf64fdb4d8d5dff4">cuda_mlp::Sigmoid</a> = 3
 }</td></tr>
<tr class="memdesc:add042d87fe3ba725b24f107b67e53742"><td class="mdescLeft">&#160;</td><td class="mdescRight">Supported activation functions.  <a href="namespacecuda__mlp.html#add042d87fe3ba725b24f107b67e53742">More...</a><br /></td></tr>
<tr class="separator:add042d87fe3ba725b24f107b67e53742"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a86bc78b6dc35b5f0b80dcf5d110249c5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a86bc78b6dc35b5f0b80dcf5d110249c5">cuda_mlp::device_set_zero</a> (CudaScalar *ptr, size_t n)</td></tr>
<tr class="memdesc:a86bc78b6dc35b5f0b80dcf5d110249c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set device memory to zero.  <a href="namespacecuda__mlp.html#a86bc78b6dc35b5f0b80dcf5d110249c5">More...</a><br /></td></tr>
<tr class="separator:a86bc78b6dc35b5f0b80dcf5d110249c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a215a45960999b21de6294e29d6d8a532"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a215a45960999b21de6294e29d6d8a532">cuda_mlp::device_copy</a> (CudaScalar *dst, const CudaScalar *src, size_t n)</td></tr>
<tr class="memdesc:a215a45960999b21de6294e29d6d8a532"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy device-to-device.  <a href="namespacecuda__mlp.html#a215a45960999b21de6294e29d6d8a532">More...</a><br /></td></tr>
<tr class="separator:a215a45960999b21de6294e29d6d8a532"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f4e970087afb17ae397b2280d231961"><td class="memItemLeft" align="right" valign="top">CudaScalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a0f4e970087afb17ae397b2280d231961">cuda_mlp::device_dot</a> (CublasHandle &amp;handle, const CudaScalar *x, const CudaScalar *y, int n)</td></tr>
<tr class="memdesc:a0f4e970087afb17ae397b2280d231961"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute dot product on device using cuBLAS.  <a href="namespacecuda__mlp.html#a0f4e970087afb17ae397b2280d231961">More...</a><br /></td></tr>
<tr class="separator:a0f4e970087afb17ae397b2280d231961"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51e81d68937e957ac0f2ab923657af35"><td class="memItemLeft" align="right" valign="top">CudaScalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a51e81d68937e957ac0f2ab923657af35">cuda_mlp::device_nrm2</a> (CublasHandle &amp;handle, const CudaScalar *x, int n)</td></tr>
<tr class="memdesc:a51e81d68937e957ac0f2ab923657af35"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute Euclidean norm on device using cuBLAS.  <a href="namespacecuda__mlp.html#a51e81d68937e957ac0f2ab923657af35">More...</a><br /></td></tr>
<tr class="separator:a51e81d68937e957ac0f2ab923657af35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1c191bf546aef9e59039713a5e2d835"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#af1c191bf546aef9e59039713a5e2d835">cuda_mlp::device_axpy</a> (CublasHandle &amp;handle, int n, CudaScalar alpha, const CudaScalar *x, CudaScalar *y)</td></tr>
<tr class="memdesc:af1c191bf546aef9e59039713a5e2d835"><td class="mdescLeft">&#160;</td><td class="mdescRight">y &lt;- alpha * x + y (AXPY) on device using cuBLAS.  <a href="namespacecuda__mlp.html#af1c191bf546aef9e59039713a5e2d835">More...</a><br /></td></tr>
<tr class="separator:af1c191bf546aef9e59039713a5e2d835"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3712a0feac483fd19d967d8f2e1ac6f8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a3712a0feac483fd19d967d8f2e1ac6f8">cuda_mlp::device_scal</a> (CublasHandle &amp;handle, int n, CudaScalar alpha, CudaScalar *x)</td></tr>
<tr class="memdesc:a3712a0feac483fd19d967d8f2e1ac6f8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scale vector x &lt;- alpha * x on device using cuBLAS.  <a href="namespacecuda__mlp.html#a3712a0feac483fd19d967d8f2e1ac6f8">More...</a><br /></td></tr>
<tr class="separator:a3712a0feac483fd19d967d8f2e1ac6f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a3644353b56e2f50f80adcfc3f4ee00"><td class="memItemLeft" align="right" valign="top">CudaScalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a6a3644353b56e2f50f80adcfc3f4ee00">cuda_mlp::activation_scale</a> (ActivationType act)</td></tr>
<tr class="memdesc:a6a3644353b56e2f50f80adcfc3f4ee00"><td class="mdescLeft">&#160;</td><td class="mdescRight">scaling factor for initialization.  <a href="namespacecuda__mlp.html#a6a3644353b56e2f50f80adcfc3f4ee00">More...</a><br /></td></tr>
<tr class="separator:a6a3644353b56e2f50f80adcfc3f4ee00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39ed9d7bc945a35120a283c58f18b234"><td class="memItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a39ed9d7bc945a35120a283c58f18b234">cuda_mlp::add_bias_kernel</a> (CudaScalar *z, const CudaScalar *b, int rows, int cols)</td></tr>
<tr class="memdesc:a39ed9d7bc945a35120a283c58f18b234"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel: add bias vector to column-major matrix.  <a href="namespacecuda__mlp.html#a39ed9d7bc945a35120a283c58f18b234">More...</a><br /></td></tr>
<tr class="separator:a39ed9d7bc945a35120a283c58f18b234"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad23fdadabcb33621d301efb8f55061b4"><td class="memItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#ad23fdadabcb33621d301efb8f55061b4">cuda_mlp::activation_kernel</a> (CudaScalar *a, int n, int act)</td></tr>
<tr class="memdesc:ad23fdadabcb33621d301efb8f55061b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel: apply activation in-place.  <a href="namespacecuda__mlp.html#ad23fdadabcb33621d301efb8f55061b4">More...</a><br /></td></tr>
<tr class="separator:ad23fdadabcb33621d301efb8f55061b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace5ac3a9a98695da4fe96eee9d7baf8d"><td class="memItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#ace5ac3a9a98695da4fe96eee9d7baf8d">cuda_mlp::activation_deriv_kernel</a> (CudaScalar *grad, const CudaScalar *a, int n, int act)</td></tr>
<tr class="memdesc:ace5ac3a9a98695da4fe96eee9d7baf8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel: multiply gradient by activation derivative.  <a href="namespacecuda__mlp.html#ace5ac3a9a98695da4fe96eee9d7baf8d">More...</a><br /></td></tr>
<tr class="separator:ace5ac3a9a98695da4fe96eee9d7baf8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81abd70005964e3cb98ae99ff665f707"><td class="memItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a81abd70005964e3cb98ae99ff665f707">cuda_mlp::diff_kernel</a> (const CudaScalar *output, const CudaScalar *target, CudaScalar *diff, int n)</td></tr>
<tr class="memdesc:a81abd70005964e3cb98ae99ff665f707"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel: diff = output - target.  <a href="namespacecuda__mlp.html#a81abd70005964e3cb98ae99ff665f707">More...</a><br /></td></tr>
<tr class="separator:a81abd70005964e3cb98ae99ff665f707"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afddab47a8654b1848c3030aef40a6634"><td class="memItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#afddab47a8654b1848c3030aef40a6634">cuda_mlp::sum_rows_kernel</a> (const CudaScalar *mat, CudaScalar *out, int rows, int cols)</td></tr>
<tr class="memdesc:afddab47a8654b1848c3030aef40a6634"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel: sum columns (rows x cols) into a row vector.  <a href="namespacecuda__mlp.html#afddab47a8654b1848c3030aef40a6634">More...</a><br /></td></tr>
<tr class="separator:afddab47a8654b1848c3030aef40a6634"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd24fc3c966441401f0f06926743e3e4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#abd24fc3c966441401f0f06926743e3e4">cuda_mlp::launch_add_bias</a> (CudaScalar *z, const CudaScalar *b, int rows, int cols)</td></tr>
<tr class="memdesc:abd24fc3c966441401f0f06926743e3e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Launch add-bias kernel.  <a href="namespacecuda__mlp.html#abd24fc3c966441401f0f06926743e3e4">More...</a><br /></td></tr>
<tr class="separator:abd24fc3c966441401f0f06926743e3e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af291a8274e02d62ea667b6dd7c595bc6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#af291a8274e02d62ea667b6dd7c595bc6">cuda_mlp::launch_activation</a> (CudaScalar *a, int n, ActivationType act)</td></tr>
<tr class="memdesc:af291a8274e02d62ea667b6dd7c595bc6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Launch activation kernel.  <a href="namespacecuda__mlp.html#af291a8274e02d62ea667b6dd7c595bc6">More...</a><br /></td></tr>
<tr class="separator:af291a8274e02d62ea667b6dd7c595bc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab07f4773848ee1516671610a538c8ae2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#ab07f4773848ee1516671610a538c8ae2">cuda_mlp::launch_activation_deriv</a> (CudaScalar *grad, const CudaScalar *a, int n, ActivationType act)</td></tr>
<tr class="memdesc:ab07f4773848ee1516671610a538c8ae2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Launch activation-derivative kernel.  <a href="namespacecuda__mlp.html#ab07f4773848ee1516671610a538c8ae2">More...</a><br /></td></tr>
<tr class="separator:ab07f4773848ee1516671610a538c8ae2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5b0352656cf797de01a1e71906318a8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#af5b0352656cf797de01a1e71906318a8">cuda_mlp::launch_diff</a> (const CudaScalar *output, const CudaScalar *target, CudaScalar *diff, int n)</td></tr>
<tr class="memdesc:af5b0352656cf797de01a1e71906318a8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Launch diff kernel.  <a href="namespacecuda__mlp.html#af5b0352656cf797de01a1e71906318a8">More...</a><br /></td></tr>
<tr class="separator:af5b0352656cf797de01a1e71906318a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a171790bf97e28b10641775d966d496e0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacecuda__mlp.html#a171790bf97e28b10641775d966d496e0">cuda_mlp::launch_sum_rows</a> (const CudaScalar *mat, CudaScalar *out, int rows, int cols)</td></tr>
<tr class="memdesc:a171790bf97e28b10641775d966d496e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Launch sum-rows kernel.  <a href="namespacecuda__mlp.html#a171790bf97e28b10641775d966d496e0">More...</a><br /></td></tr>
<tr class="separator:a171790bf97e28b10641775d966d496e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
